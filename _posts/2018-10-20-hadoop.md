---
layout:       post
title:        "Hadoop 安装及配置"
subtitle:     "Hadoop Installation & Configuration"
date:         "2018-10-20"
header-img:   "img/post/hadoop.jpeg"
catalog:      true
header-mask:         0.6
tags:
    - hadoop
    - 安装
    - 配置
---
# 安装方式、版本和操作系统

## Hadoop 安装方式
- **单机模式**：Hadoop 默认模式为非分布式模式（本地模式），无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。
- **伪分布式模式**：Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，结点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。
- **分布式模式**：使用多个结点构成集群环境来运行Hadoop。

## Hadoop 版本
Hadoop 有两个主要版本，Hadoop 1.x 和 Hadoop 2.x 系列。
Hadoop 2.0 即第二代 Hadoop 为克服 Hadoop1.0 中的不足修正了架构，并不断更新。
我们研究学习时，使用的是 Hadoop 2.0 以后的版本。

## 操作系统

我采用的是 CentOS 7 64位 的 Linux 发行版。
> CentOS 是一个基于 Red Hat Linux 提供的可自由使用源代码的企业级 Linux 发行版本。
> CentOS 是 RHEL（Red Hat Enterprise Linux）源代码再编译的产物，而且在 RHEL 的基础上修正了不少已知的 Bug ，相对于其他 Linux 发行版，其稳定性值得信赖。

# Hadoop 开发环境部署
如何安装 CentOS 此处不在赘述，下面直接步入正题——部署Hadoop 开发环境。

## 创建 hadoop 用户
装好了 CentOS 系统之后，在安装 Hadoop 前还需要做一些必备工作。

如果你安装 CentOS 的时候不是用的 hadoop 用户，那么需要增加一个名为 hadoop 的用户。

首先打开终端模拟器，点击左上角的 `应用程序` > `系统工具`> `终端`。

然后，在终端中输入 su ，按回车，输入 root 密码以 root 用户登录，接着执行命令创建可以登陆 hadoop 用户，并使用 /bin/bash 作为 shell：
```sh
su        # 以 root 用户登录
useradd -m hadoop -s /bin/bash   # 创建新用户 hadoop
```

继续修改 hadoop 用户的密码，按提示输入两次密码。
```sh
passwd hadoop
```

## 配置 SSH 无密码登陆
集群、单节点模式下 Hadoop 作业的整个处理过程，都是利用 ssh 实现通讯的，就算是本机也是在 ssh 下进行的，为了让Hadoop各节点能够正常通信，我们需要配置 ssh 免登陆

一般情况下，CentOS 默认已安装了 SSH client、SSH server，打开终端执行如下命令进行检验
```sh
rpm -qa | grep ssh
```

若需安装，则可通过 yum 进行安装
```sh
sudo yum install openssh-clients
sudo yum install openssh-server
```

最后测试 ssh 是否可用
```sh
ssh localhost
```

如果有以前配置过 ssh，请先删除原来的 ssh 配置
```sh
rm -rf ~/.ssh/id*
```

在本地主机上生成 ssh 公钥，我们不设置登录密码，输入如下命令，一路回车就行了
```sh
ssh-keygen -t rsa
```

然后会在 `~/.ssh` 目录下生成一个密钥对 `id_rsa` 和 `id_rsa.pub`。

接着将生成的公钥 `id_rsa.pub` 中的信息，追加到想要登录到的远程主机的授权认证文件 `authorized_keys` 中，就实现免密码登录了。

## 设置 IP 域名映射（建议）
在生产环境下 hadoop 的配置中是不允许进行 IP 变更的，长长的 IP 也不利于我们区分集群中的各台主机。于是为了配置方便，我们要为每台主机设置一个域名比如 `hadoopm`，通过使用域名代替 IP 来配置 Hadoop 的启动参数


配置主机名映射，修改 hosts 文件
```sh
vi /etc/hosts
```
在里面追加映射配置
```sh
192.168.1.111   hadoopm
```
*请将 192.168.1.111 换为你的IP，注意不要写成**还回地址***

为了一致性我们将主机名也一起进行修改
```sh
vim /etc/hostname #将 localhost 改为 hadoopm
```

## 安装 Java 环境
Java 环境我们可以选择 Oracle JDK 也可以选择 OpenJDK。
CentOS 7 安装后自带 jre，但是光有 jre 是不够的，我们需要用到 jre 之外的一些工具，所以需要安装整个 jdk。
我们通过 CentOS 的软件包管理器 yum 来安装 JDK：
```sh
sudo yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel
```

安装完成后，默认情况下 java-1.8.0-openjdk 被安装在路径 `/usr/lib/jvm/java-1.8.0-openjdk` 下。我们也可以通过下面的命令查看安装路径：
```sh
rpm -ql java-1.8.0-openjdk-devel | grep '/bin/javac'
```

*安装路径可能会有出入，但是默认情况下会将真正的安装路径链接到 `/usr/lib/jvm/java-x.y.z-openjdk`*

然后我们在 `~/.bashrc` 文件中配置 JAVA_HOME 环境变量：
```sh
vim ~/.bashrc
```

将下面的配置追加到文件中：
```sh
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
```

然后启用配置，让环境变量生效：
```sh
source ~/.bashrc
```

最后，我们可以通过以下命令检验配置是否成功：
```sh
echo $JAVA_HOME    # 检验环境变量
java -version
```
如果输出对应的信息则表示安装成功。

## 安装 Hadoop 2
hadoop 国内镜像
- [清华大学开源软件镜像](https://mirrors.cnnic.cn/apache/hadoop/common/?_blank)
- [北京理工大学开源软件镜像](https://mirror.bit.edu.cn/apache/hadoop/common/?_blank)

使用 wget 下载 `hadoop-2.9.1.tar.gz`：
```sh
wget https://mirrors.cnnic.cn/apache/hadoop/common/stable/hadoop-2.9.1.tar.gz
```

完成下载后，将其解压到 `/usr/local/` 目录下。方便配置，修改所属，并删去 hadoop 的版本号：
```sh
sudo tar zxvf hadoop-2.9.1.tar.gz -C /usr/local
cd /usr/local
sudo chown -R hadoop:hadoop hadoop-2.9.1
sudo mv hadoop-2.9.1 hadoop
```

最后我们来检验 hadoop 是否可用：
```sh
cd /usr/local/hadoop
./bin/hadoop version
```

## Hadoop 单机配置(非分布式)
在默认情况下，我们安装好的 Hadoop 处于单机模式。无需进行任何配置即可运行。单机模式下之后生成一个 Java 进程，方便调试。

## Hadoop 伪分布式配置
Hadoop 一款是分布式系统应用，由于我们只是进行简单的实验测试，没必要做集群。我们可以通过修改配置文件来启动 Hadoop 的伪分布式模式。

Hadoop 的配置文件位于 `/usr/local/hadoop/etc/` 目录下，伪分布式模式我们只需要修改以下三个配置文件：
 - core-site.xml
 - hdfs-site.xml
 - yarn-site.xml

各文件对应的相关配置如下：

core-site.xml
```xml
<configuration>
        <property>
                <!-- Hadoop 临时文件目录 -->
                <name>hadoop.tmp.dir</name>
                <value>/home/hadoop/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoopm:9000</value>
        </property>
</configuration>
```

hdfs-site.xml
```xml
<configuration>
        <property>
                <!-- 文件副本数量，默认情况下一个文件会备份 3 份 -->
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <!-- 名称结点路径，没有它数据将无法查找 -->
                <name>dfs.namenode.name.dir</name>
                <value>file:///usr/local/hadoop/dfs/name</value>
        </property>
        <property>
                <!-- 数据文件结点路径 -->
                <name>dfs.datanode.data.dir</name>
                <value>file:///usr/local/hadoop/dfs/data</value>
        </property>
        <property>
                <!-- 名称服务的 http 访问地址 -->
                <name>dfs.namenode.http-address</name>
                <value>hadoopm:50070</value>
        </property>
        <property>
                <!-- 第二名称结点 -->
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoopm:50090</value>
        </property>
        <property>
                <!-- 授权认证，学习测试阶段不要设置 -->
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
</configuration>
```

yarn-site.xml
```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.admin.address</name>
                <value>hadoopm:8033</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
                <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
                <name>yarn.resourcemanager.resource-tracker.address</name>
                <value>hadoopm:8025</value>
        </property>
        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>hadoopm:8030</value>
        </property>
        <property>
                <name>yarn.resourcemanager.address</name>
                <value>hadoopm:8050</value>
        </property>
        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>hadoopm:8030</value>
        </property>
        <property>
                <name>yarn.resourcemanager.webapp.address</name>
                <value>hadoopm:8088</value>
        </property>
        <property>
                <name>yarn.resourcemanager.webapp.https.address</name>
                <value>hadoopm:8090</value>
        </property>
</configuration>
```

Hadoop 属于分布式开发环境，如果考虑到日后要进行集群搭建，建议在`/usr/local/hadoop/etc/hadoop/`目录中创建一个 master 文件，在里面写入主机的名称，单机环境下不配置也无妨。

接下来修改 worker 文件中的主机名称

由于此时是将所有的 namenode、datanode 都保存到 hadoop 目录中，保险起见由我们自己来创建目录
```sh
cd /usr/local/hadoop #进入Hadoop的安装目录
mkdir -p dfs/name dfs/data #创建两个目录
```

## 格式化 HDFS 文件系统

*注意: 当 hadoop 配置文件出错时需要重新配置时，请保证这两个目录彻底清除之后再格式化 HDFS 文件系统*

