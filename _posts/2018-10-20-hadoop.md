---
layout:       post
title:        "Hadoop 安装及伪分布式配置"
subtitle:     "CentOS7/Hadoop2.6.0"
date:         "2018-10-20"
header-img:   "img/post/hadoop.jpeg"
catalog:      true
tags:
    - hadoop
---

# Hadoop 部署简介
Hadoop 的安装方式有三种，分别是单机模式、伪分布式模式、分布式模式。

## 安装方式

- **单机模式**：Hadoop 默认模式为非分布式模式（本地模式），无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。
- **伪分布式模式**：Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。
- **分布式模式**：使用多个节点构成集群环境来运行Hadoop。

## Hadoop 版本
Hadoop 有两个主要版本，Hadoop 1.x 和 Hadoop 2.x 系列。Hadoop2.0 即第二代 Hadoop 为克服 Hadoop1.0 中的不足修正了一些架构，并不断更新。

## 系统环境
我采用的是 CentOS 7 64位 的 Linux 发行版
> CentOS 是一个基于Red Hat Linux 提供的可自由使用源代码的企业级Linux发行版本。

# Hadoop 开发环境部署
## 创建 hadoop 用户
装好了 CentOS 系统之后，在安装 Hadoop 前还需要做一些必备工作。

如果你安装 CentOS 的时候不是用的 hadoop 用户，那么需要增加一个名为 hadoop 的用户。

首先打开终端模拟器，点击左上角的 `应用程序` > `系统工具`> `终端`

在终端中输入 su ，按回车，输入 root 密码以 root 用户登录，接着执行命令创建可以登陆 hadoop 用户，并使用 /bin/bash 作为 shell

```sh
su        # 以 root 用户登录
useradd -m hadoop -s /bin/bash   # 创建新用户 hadoop
```

继续修改 hadoop 用户的密码，按提示输入两次密码。

```sh
passwd hadoop
```

## 配置 SSH 无密码登陆

集群、单节点模式下 Hadoop 作业的整个处理过程，都是利用 ssh 实现通讯的，就算是本机也是在 ssh 下进行的，为了让Hadoop各节点能够正常通信，我们需要配置 ssh 免登陆

一般情况下，CentOS 默认已安装了 SSH client、SSH server，打开终端执行如下命令进行检验
```sh
rpm -qa | grep ssh
```

若需安装，则可通过 yum 进行安装
```sh
sudo yum install openssh-clients
sudo yum install openssh-server
```
最后测试 ssh 是否可用
```sh
ssh localhost
```
如果有以前配置过 ssh，请先删除原来的 ssh 配置
```sh
rm -rf ~/.ssh/id*
```
在本地主机上生成 ssh 公钥，我们不设置登录密码，输入如下命令，一路回车就行了
```sh
ssh-keygen -t rsa
```
然后会在 `~/.ssh` 目录下生成一个密钥对 `id_rsa` 和 `id_rsa.pub`。

接着将生成的公钥 `id_rsa.pub` 中的信息，追加到想要登录到的远程主机的授权认证文件 authorized_keys 中就可以实现免密码登录了。

## 设置 IP 域名映射（建议）
在生产环境下 hadoop 的配置中是不允许进行 IP 变更的，长长的 IP 也不利于我们区分集群中的各台主机。于是为了配置方便，我们要为每台主机设置一个域名比如 `hadoopm`，通过使用域名代替 IP 来配置 Hadoop 的启动参数


配置主机名映射，修改 hosts 文件
```sh
vi /etc/hosts
```
在里面追加映射配置
```sh
192.168.1.111   hadoopm
```
*请将 192.168.1.111 换为你的IP，注意不要写成**还回地址***

为了一致性我们将主机名也一起进行修改
```sh
vim /etc/hostname #将 localhost 改为 hadoopm
```

## 安装Java环境
```sh
sudo yum install java-1.8.0-openjdk java-1.8.0-openjdk-devel
rpm -ql java-1.8.0-openjdk-devel | grep '/bin/javac'
vim ~/.bashrc
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
source ~/.bashrc
echo $JAVA_HOME
java -version
```
## 安装 Hadoop2

## Hadoop单机配置(非分布式)
在默认情况下，我们安装好的 Hadoop 处于单机模式，我们可以通过修改配置文件启动 Hadoop 的为分布式模式。
# Hadoop 伪分布式配置
Hadoop 一款是分布式系统应用，由于我们只是进行简单的实验测试，没必要做集群。所以只需要使用所谓的伪分布式方式来配置 Hadoop


Hadoop 的配置文件位于 `./hadoop/etc/`，伪分布式模式我们需要修改以下三个配置文件：
 - core-site.xml
 - yarn-site.xml
 - hdfs-site.xml

伪分布式模式 Hadoop 相关配置如下：

core-site.xml
```xml
<configuration>
        <property>
                <!-- Hadoop 临时文件目录 -->
                <name>hadoop.tmp.dir</name>
                <value>/home/hadoop/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://hadoopm:9000</value>
        </property>
</configuration>
```
hdfs-site.xml
```xml
<configuration>
        <property>
                <!-- 文件副本数量，默认情况下一个文件会备份 3 份 -->
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <!-- 名称结点路径，没有它数据将无法查找 -->
                <name>dfs.namenode.name.dir</name>
                <value>file:///usr/local/hadoop/dfs/name</value>
        </property>
        <property>
                <!-- 数据文件结点路径 -->
                <name>dfs.datanode.data.dir</name>
                <value>file:///usr/local/hadoop/dfs/data</value>
        </property>
        <property>
                <!-- 名称服务的 http 访问地址 -->
                <name>dfs.namenode.http-address</name>
                <value>hadoopm:50070</value>
        </property>
        <property>
                <!-- 第二名称结点 -->
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoopm:50090</value>
        </property>
        <property>
                <!-- 授权认证，学习测试阶段不要设置 -->
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
</configuration>
```

配置结点任务调度方式   
yarn-site.xml
```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.admin.address</name>
                <value>hadoopm:8033</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services.mapreduce_shuffle.class</name>
                <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
                <name>yarn.resourcemanager.resource-tracker.address</name>
                <value>hadoopm:8025</value>
        </property>
        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>hadoopm:8030</value>
        </property>
        <property>
                <name>yarn.resourcemanager.address</name>
                <value>hadoopm:8050</value>
        </property>
        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>hadoopm:8030</value>
        </property>
        <property>
                <name>yarn.resourcemanager.webapp.address</name>
                <value>hadoopm:8088</value>
        </property>
        <property>
                <name>yarn.resourcemanager.webapp.https.address</name>
                <value>hadoopm:8090</value>
        </property>
</configuration>
```

Hadoop 属于分布式开发环境，如果考虑到日后要进行集群搭建，建议在`/usr/local/hadoop/etc/hadoop/`目录中创建一个 master 文件，在里面写入主机的名称，单机环境下不配置也无妨。

接下来修改 worker 文件中的主机名称

由于此时是将所有的 namenode、datanode 都保存到 hadoop 目录中，保险起见由我们自己来创建目录
```sh
cd /usr/local/hadoop #进入Hadoop的安装目录
mkdir -p dfs/name dfs/data #创建两个目录
```

## 格式化 HDFS 文件系统

*注意: 当 hadoop 配置文件出错时需要重新配置时，请保证这两个目录彻底清除之后再格式化 HDFS 文件系统*

