---
layout:       post
title:        Hive的安装部署
subtitle:     大数据平台建设系列
date:         2020-2-22
header-img:   img/post/caffee.jpg
header-mask:  0.5
catalog:      true
tags:
    - hadoop
    - hive
---

### 获取Hive
从清华镜像源下载Apache的hive二进制压缩包到家目录的download目录下
```sh
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-2.3.6/apache-hive-2.3.6-bin.tar.gz -P ~/download
```
### 解压缩
将hive解压到`/usr/local`目录下
```sh
sudo tar zxvf apache-hive-2.3.6-bin.tar.gz -C /usr/local/
```

### 添加环境变量
将hive的主目录添加到环境变量中，编辑家目录下的`.bashrc`文件
```sh
vi ~/.bashrc
```
输入下面的环境变量
```sh
export HIVE_HOME=/usr/local/apache-hive-2.3.6-bin
export PATH=$HIVE_HOME/bin:$PATH
```
最后更新环境变量
```sh
source ~/.bashrc
```

### 修改配置文件
切换到hive的配置文件目录下，拷贝配置文件的模板，以便接下来进行修改
```sh
cd $HIVE_HOME/conf
cp hive-env.sh{.template,}
cp hive-{default.xml.template,site.xml}
cp hive-log4j2.properties{.template,}
cp hive-exec-log4j2.properties{.template,}
cp beeline-log4j2.properties{.template,}
```
首先修改`hive-env.sh`，找到`HADOOP_HOME`，修改为相应路径，如
```sh
HADOOP_HOME=/usr/local/hadoop
```

然后是`hive-site.xml`，添加如下配置
```xml
<configuration>
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true</value>
    <description>the URL of Mysql database</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>123456</value>
  </property>

  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/hive/warehouse</value>
  </property>

  <property>
    <name>hive.exec.scratchdir</name>
    <value>/hive/tmp</value>
  </property>

  <property>
    <name>hive.querylog.location</name>
    <value>/hive/log</value>
  </property>
</configuration>
```

### 安装MySQL Driver
下载MySQL Driver
```sh
wget https://mirrors.tuna.tsinghua.edu.cn/mysql/downloads/Connector-J/mysql-connector-java-5.1.48.zip -P ~/download/
```
解压MySQL Driver，并复制到hive的库目录下
```sh
unzip mysql-connector-java-5.1.48.zip
cp mysql-connector-java-5.1.48/mysql-connector-java-5.1.48-bin.jar $HIVE_HOME/lib
```

### 创建hive目录
在HDFS上创建相关目录，并设置读写权限
```sh
hadoop fs -mkdir -p /hive/tmp /hive/log /hive/warehouse
hadoop fs -chmod 777 /hive/tmp
```

### 初始化元数据
执行如下指令初始化元数据相关信息
```sh
schematool --dbType mysql --initSchema
```
显示如下信息表示成功
```
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.   SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:        jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true
Metastore Connection Driver :    com.mysql.jdbc.Driver
Metastore connection User:       root
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.mysql.sql
Initialization script completed
schemaTool completed
```

### 启动服务并连接
启动hive的metastore service（元数据服务）
```sh
hive --service metastore &
```
如果看到如下信息，说明服务已经成功启动了
```
2020-02-22 20:06:42: Starting Hive Metastore Server
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.   SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
```


我们可以尝试使用hive客户端进行连接
```sh
hive
```


启动hiveserver2，用于支持JDBC的查询服务
```sh
hiveserver2 &
```
看到如下内容，表示启动成功
```
2020-02-22 20:20:53: Starting HiveServer2
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
```
通过beeline连接hiveserver2
```sh
beeline -u jdbc:hive2://localhost:10000 hadoop
```
